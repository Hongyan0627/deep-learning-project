{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/a/data/mango/environments/newtf/lib/python2.7/site-packages/dicom/__init__.py:53: UserWarning: \n",
      "This code is using an older version of pydicom, which is no longer \n",
      "maintained as of Jan 2017.  You can access the new pydicom features and API \n",
      "by installing `pydicom` from PyPI.\n",
      "See 'Transitioning to pydicom 1.x' section at pydicom.readthedocs.org \n",
      "for more information.\n",
      "\n",
      "  warnings.warn(msg)\n",
      "/a/data/mango/environments/newtf/lib/python2.7/site-packages/sklearn/externals/joblib/_multiprocessing_helpers.py:28: UserWarning: [Errno 13] Permission denied.  joblib will operate in serial mode\n",
      "  warnings.warn('%s.  joblib will operate in serial mode' % (e,))\n",
      "/a/data/mango/environments/newtf/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "import sys,os\n",
    "import numpy as np\n",
    "import dicom\n",
    "import glob\n",
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn import cross_validation\n",
    "from lightgbm.sklearn import LGBMRegressor\n",
    "#from Vgg19 import VGG19\n",
    "from resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "#from imagenet_utils import preprocess_input\n",
    "#from PIL import Image\n",
    "#from resizeimage import resizeimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import errno\n",
    "def make_sure_path_exists(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exception:\n",
    "        if exception.errno != errno.EEXIST:\n",
    "            raise\n",
    "EXPERIMENT_NUMBER = '005' \n",
    "\n",
    "#Put here the path where you downloaded all kaggle data\n",
    "DATA_PATH='data/'\n",
    "\n",
    "# Path and variables\n",
    "STAGE1_LABELS=DATA_PATH + 'stage1_labels.csv'\n",
    "STAGE1_SAMPLE_SUBMISSION=DATA_PATH + 'stage1_sample_submission.csv'\n",
    "STAGE1_FOLDER=DATA_PATH + 'stage1/'\n",
    "FEATURE_FOLDER=DATA_PATH + 'features/features' + EXPERIMENT_NUMBER + '/'\n",
    "SUBMIT_OUTPUT='submit' + EXPERIMENT_NUMBER + '.csv'\n",
    "\n",
    "make_sure_path_exists(FEATURE_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Timer class\n",
    "class Timer(object):\n",
    "    def __enter__(self):\n",
    "        self.start()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        self.stop()\n",
    "\n",
    "    def start(self):\n",
    "        self.start = time.clock()\n",
    "\n",
    "    def stop(self):\n",
    "        self.end = time.clock()\n",
    "        self.interval = self.end - self.start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_3d_data(path):\n",
    "    slices = [dicom.read_file(path + '/' + s) for s in os.listdir(path)]\n",
    "    slices.sort(key=lambda x: int(x.InstanceNumber))\n",
    "    return np.stack([s.pixel_array for s in slices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_id(path, plot_data=False):\n",
    "    sample_image = get_3d_data(path)\n",
    "\n",
    "    sample_image[sample_image == -2000] = 0\n",
    "    # downsample\n",
    "    sample_image = sample_image[:94]\n",
    "    print \"sample_image shape:\"\n",
    "    print sample_image.shape\n",
    "    #if plot_data:\n",
    "    #    f, plots = plt.subplots(4, 5, sharex='col', sharey='row', figsize=(10, 8))\n",
    "\n",
    "    batch = []\n",
    "    cnt = 0\n",
    "    dx = 40\n",
    "    ds = 512\n",
    "    for i in range(0, sample_image.shape[0] - 3, 3):\n",
    "        tmp = []\n",
    "        for j in range(3):\n",
    "            img = sample_image[i + j]\n",
    "            img = 255.0 / np.amax(img) * img\n",
    "            img = cv2.equalizeHist(img.astype(np.uint8))\n",
    "            img = img.astype(np.uint8)\n",
    "            img = img[dx: ds - dx, dx: ds - dx]\n",
    "            img = cv2.resize(img, (224, 224))\n",
    "            #img = resizeimage.resize_crop(img, [224, 224])\n",
    "            #img = np.resize(img, (224,224))\n",
    "            tmp.append(img)\n",
    "\n",
    "        tmp = np.array(tmp)\n",
    "        tmp = np.swapaxes(tmp,0,2) #we need to make \"color\" dimension last I think\n",
    "        batch.append(np.array(tmp))\n",
    "\n",
    "#         if plot_data:\n",
    "#             if cnt < 20:\n",
    "#                 plots[cnt // 5, cnt % 5].axis('off')\n",
    "#                 plots[cnt // 5, cnt % 5].imshow(tmp[0,:,:], cmap='gray')\n",
    "#             cnt += 1\n",
    "\n",
    "#     if plot_data: plt.show()\n",
    "        \n",
    "    batch = np.array(batch, dtype='int')\n",
    "    return batch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = ResNet50(weights='imagenet', include_top=False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_feature(verbose=False):\n",
    "    model = get_model()\n",
    "    for folder in glob.glob(STAGE1_FOLDER+'*'):\n",
    "        foldername = os.path.basename(folder)\n",
    "        if os.path.isfile(FEATURE_FOLDER+foldername+'.npy'):\n",
    "            if verbose:print('Features in %s already computed' %(FEATURE_FOLDER+foldername))\n",
    "            continue\n",
    "        batch = get_data_id(folder)\n",
    "        if verbose:\n",
    "            print (\"Batch size:\")\n",
    "            print (batch.shape)\n",
    "        feats = []\n",
    "        for i in range(batch.shape[0]):\n",
    "            temp = batch[i]\n",
    "            temp = np.expand_dims(temp, axis = 0)\n",
    "            feat = model.predict(temp, batch_size = 52, verbose = 1)\n",
    "            print \"feat.shape\"\n",
    "            print feat.shape\n",
    "            feats.append(feat)\n",
    "        print \"feats.shape\"\n",
    "        print len(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_features(verbose=False):\n",
    "    model = get_model()\n",
    "    for folder in glob.glob(STAGE1_FOLDER+'*'):\n",
    "        foldername = os.path.basename(folder)\n",
    "        if os.path.isfile(FEATURE_FOLDER+foldername+'.npy'):\n",
    "            if verbose: print(\"Features in %s already computed\" % (FEATURE_FOLDER+foldername))\n",
    "            continue\n",
    "        batch = get_data_id(folder)\n",
    "        print (\"batch shape\")\n",
    "        print batch.shape\n",
    "        if verbose:\n",
    "            print(\"Batch size:\")\n",
    "            print(batch.shape)\n",
    "        \n",
    "        feats = model.predict(batch, batch_size=52, verbose=1)\n",
    "        print foldername\n",
    "        print feats.shape\n",
    "\n",
    "        if verbose:\n",
    "            print(feats.shape)\n",
    "            print(\"Saving features in %s\" % (FEATURE_FOLDER+foldername))\n",
    "        np.save(FEATURE_FOLDER+foldername, feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        \n",
    "#%%time\n",
    "# Calculate features\n",
    "calc_features(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add LSTM to model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "#import numpy as np\n",
    "\n",
    "# feats shape (31, 1,1,2048) for every patient\n",
    "# each feat for every patient with shape (1,1,1,2048), so input_dim = 4\n",
    "# timesteps, total 31 feats for every patient\n",
    "# patient number:\n",
    "def train_lstm():\n",
    "    data_dim = 1\n",
    "    timesteps = 1 \n",
    "    num_classes = 2\n",
    "\n",
    "    # expected input data shape: (batch_size, timesteps, data_dim)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(32, return_sequences=False,\n",
    "                   input_shape=(1, 2048)))  # returns a sequence of vectors of dimension 32\n",
    "    #model.add(LSTM(32, return_sequences=True))  # returns a sequence of vectors of dimension 32\n",
    "    #model.add(LSTM(32))  # return a single vector of dimension 32\n",
    "    model.add(Dense(1, activation='softmax')) #  is number of classes\n",
    "\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    df  = pd.read_csv(STAGE1_LABELS)\n",
    "    y = df['cancer'].as_matrix()\n",
    "    print y.shape\n",
    "    x =  np.array([np.mean(np.load(FEATURE_FOLDER+'%s.npy' % str(id)), axis=0).flatten() for id in df['id'].tolist()])\n",
    "    x = x.reshape(x.shape[0], 1, x.shape[1])\n",
    "    x_train, x_val, y_train, y_val = cross_validation.train_test_split(x, y, random_state=42, stratify=y,\n",
    "                                                                       test_size=0.20)\n",
    "    print x_train.shape\n",
    "    print y_train.shape\n",
    "    print x_val.shape\n",
    "    print y_val.shape\n",
    "\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=64, epochs=1,\n",
    "              validation_data=(x_val, y_val))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_training_lstm(verbose=True):\n",
    "    with Timer() as t:\n",
    "        model = train_lstm()\n",
    "    if verbose: print(\"Training took %.03f sec.\\n\" % t.interval)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_prediction_lstm(model, verbose=True):    \n",
    "    df = pd.read_csv(STAGE1_SAMPLE_SUBMISSION)\n",
    "    x = np.array([np.mean(np.load((FEATURE_FOLDER+'%s.npy') % str(id)), axis=0).flatten() for id in df['id'].tolist()])\n",
    "    x = x.reshape(x.shape[0], 1, x.shape[1])\n",
    "    with Timer() as t:\n",
    "        pred = model.predict(x)\n",
    "    if verbose: print(\"Prediction took %.03f sec.\\n\" % t.interval)\n",
    "    df['cancer'] = pred\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_results(df):\n",
    "    df.to_csv(SUBMIT_OUTPUT, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1397,)\n",
      "(1117, 1, 2048)\n",
      "(1117,)\n",
      "(280, 1, 2048)\n",
      "(280,)\n",
      "Train on 1117 samples, validate on 280 samples\n",
      "Epoch 1/1\n",
      "1117/1117 [==============================] - 0s - loss: 0.7413 - acc: 0.2587 - val_loss: 0.7393 - val_acc: 0.2607\n",
      "Training took 2.710 sec.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = compute_training_lstm(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction took 0.230 sec.\n",
      "\n",
      "Results:\n"
     ]
    }
   ],
   "source": [
    "df = compute_prediction_lstm(model)\n",
    "print(\"Results:\")\n",
    "df.head()\n",
    "save_results(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
